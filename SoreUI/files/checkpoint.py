# Form implementation generated from reading ui file 'interface.ui'
#
# Created by: PyQt6 UI code generator 6.7.1
#
# WARNING: Any manual changes made to this file will be lost when pyuic6 is
# run again.  Do not edit this file unless you know what you are doing.
import sys
from PyQt6 import QtCore, QtGui, QtWidgets
from PyQt6.QtWidgets import *
from PyQt6.QtGui import *
from PyQt6.QtCore import *
import speech_recognition as sr
import pyaudio
from threading import Thread
import threading
import difflib
import pyttsx3
import numpy as np
import random
import math
import time


stop_flag = threading.Event()
keyword = "camel"

engine = pyttsx3.init()
engine.setProperty("rate",175)
engine.setProperty("voice",engine.getProperty("voices")[1].id)
r=sr.Recognizer()
class AudioCaptureThread(QThread):
    audio_data_signal = pyqtSignal(np.ndarray)  # Signal to send audio data

    def __init__(self, sample_rate=44100, chunk_size=1024):
        super().__init__()
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.running = True

    def run(self):
        """Capture audio in a loop using PyAudio."""
        try:
            audio_interface = pyaudio.PyAudio()
            stream = audio_interface.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )

            while self.running:
                # Read audio data
                audio_chunk = stream.read(self.chunk_size, exception_on_overflow=False)
                audio_data = np.frombuffer(audio_chunk, dtype=np.int16)

                # Normalize audio data
                normalized_data = audio_data / np.iinfo(np.int16).max

                # Emit normalized audio data
                self.audio_data_signal.emit(normalized_data)

            # Stop stream
            stream.stop_stream()
            stream.close()
            audio_interface.terminate()

        except Exception as e:
            print(f"Error in audio thread: {e}")

    def stop(self):
        """Stop the audio capture loop."""
        self.running = False
        self.wait()

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        
        self.setObjectName("MainWindow")
        self.setFixedSize(500, 750)
        font = QtGui.QFont()
        font.setFamily("Noto Sans")
        self.setFont(font)
        self.setStyleSheet("    * {\n"
"color: #e0e5ec;\n"
"border-color:#9461fd;\n"
"\n"
"}\n"
"QWidget{\n"
"background: none;\n"
"background-repeat: no-repeat;\n"
"}\n"
"QTextBrowser{background:none}\n"
"QPushButton {    \n"
"    text-decoration: none;\n"
"    border-radius: 15px;\n"
"    background-color: rgba(0,0,0,0.1);\n"
"    border: 1px solid rgba(255, 255, 255, 0.5);\n"
"    color: rgba(255, 255, 255, 0.8);\n"
"    font-size: 14px;\n"
"    letter-spacing: 2px;\n"
"    text-transform: uppercase;\n"
"    background: none;\n"
"}\n"
"QPushButton:hover {\n"
"    background-color: rgba(255, 255, 255, 0.2);\n"
"}\n"
"QPushButton:before {\n"
"  background: none;\n"
"  border: 4px solid #fff;\n"
"  content: \"\";\n"
"  display: block;\n"
"  position: absolute;\n"
"  pointer-events: none;\n"
"}\n"
"\n"
"QPushButton:after{\n"
"content: \'\';\n"
"  position: absolute;\n"
"  inset: 0;\n"
"  border-radius: inherit;\n"
"  opacity: 0.6;\n"
"}\n"
"\n"
"QLabel {\n"
"    background:transparent;\n"
"}")
        self.centralwidget = QtWidgets.QWidget(parent=self)
        self.centralwidget.setObjectName("centralwidget")
        self.pushtotalk = QtWidgets.QPushButton(parent=self.centralwidget)
        self.pushtotalk.setGeometry(QtCore.QRect(130, 90, 250, 250))
        self.pushtotalk_defaultstylesheet="""QPushButton {
    border-radius: 125%;
   border-width: 5px;
position:relative;
    border-style: solid;
    border-color:#9461fd;
    background-image:url(./data/darkpurpleback.jpg);
    subcontrol-position: right center;
    subcontrol-origin: padding;
}
"""
        self.pushtotalk.setStyleSheet(self.pushtotalk_defaultstylesheet)
        self.pushtotalk.setObjectName("pushtotalk")
        self.is_talking = False
        self.waveform_offset = 0
        self.wavefrom_amplitude = 20
        self.timer = QTimer()
        self.timer.timeout.connect(self.update)
        self.timer.start(50)
        self.wave_amplitude = 10  # Height of waveform peaks/  maximum:20
        self.num_points = 360  # Number of points in the circle
        self.frequency = 10  # Number of waveform oscillations
        self.audio_data = np.zeros(360)
        self.audio_thread = AudioCaptureThread()
        self.audio_thread.audio_data_signal.connect(self.update_audio_data)
        self.audio_thread.start()
        self.pushtotalk_dropshadow = self.create_dropshadow(self.pushtotalk,QColor("#4003e6"),100,10,10)
        self.pushtotalk.setGraphicsEffect(self.pushtotalk_dropshadow)
        self.pushtotalk.pressed.connect(self.istalking)
        self.textresponse = QtWidgets.QTextBrowser(parent=self.centralwidget)
        self.textresponse.setGeometry(QtCore.QRect(80, 370, 350, 250))
        self.textresponse.setStyleSheet("QTextBrowser{background:rgba(0,0,0,0);}")
        self.textresponse.setObjectName("textresponse")
        self.switchtotextmodebtn = QtWidgets.QPushButton(parent=self.centralwidget)
        self.switchtotextmodebtn.setGeometry(QtCore.QRect(170, 650, 171, 51))
        self.switchtotextmodebtn.setObjectName("switchtotextmodebtn")
        self.credits = QtWidgets.QLabel(parent=self.centralwidget)
        self.credits.setGeometry(QtCore.QRect(10, 720, 91, 16))
        self.credits.setStyleSheet("")
        self.credits.setObjectName("credits")
        self.setCentralWidget(self.centralwidget)
        self.retranslateUi(self)
        QtCore.QMetaObject.connectSlotsByName(self)
    # def paintEvent(self,event):
    #     painter = QPainter(self)
    #     painter.setPen(QPen(QColor(255,0,0),2))
    #     points = []
    #     button_rect = self.pushtotalk.geometry()
        
    #     for i in range(button_rect.width()):
    #         x = button_rect.x() + i
    #         y = button_rect.y() + button_rect.height()//2 + self.wavefrom_amplitude * math.sin(i/10+self.waveform_offset)
    #         points.append(QPoint(x,round(y)))
        
    #     painter.drawPolyline(points)
    #     self.waveform_offset+=0.1
    def update_audio_data(self, new_audio_data):
        """Receive audio data from the thread and update the waveform."""
        # Resample to 360 points to match the waveform size
        self.audio_data = np.interp(
            np.linspace(0, len(new_audio_data), 360),
            np.arange(len(new_audio_data)),
            new_audio_data
        )
    def paintEvent(self, event):
        """Paint the animated waveform around the button."""
        super().paintEvent(event)
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        background_pixmap = QPixmap("./data/darkpurplebackblured.png")  # Replace with your image path
        if background_pixmap.isNull():
            painter.fillRect(self.rect(), QColor(50, 50, 50))  # Solid gray fallback
        else:
            painter.drawPixmap(self.rect(), background_pixmap)
        painter.drawPixmap(self.rect(), background_pixmap)
        # Get button geometry
        button_rect = self.pushtotalk.geometry()
        button_center = button_rect.center()
        button_radius = button_rect.width() // 2
        wave_radius = button_radius+20  # Distance from the button
        if len(self.audio_data) < 360:
            print("Error: Insufficient audio data.")
            return
        # Create the waveform path
        waveform = QPolygonF()
        for angle in range(360):
            theta = np.radians(angle)
            amplitude = self.audio_data[angle] * 150  # Scaling for visibility
            x = button_center.x() + (wave_radius + amplitude) * np.cos(theta)
            y = button_center.y() + (wave_radius + amplitude) * np.sin(theta)
            waveform.append(QPointF(round(x), round(y)))

        # Ensure the path closes by appending the first point to the end
        waveform.append(waveform[0])
        self.pushtotalk.setStyleSheet(self.pushtotalk_defaultstylesheet)
        # 1. Neon-style Gradient: Dark purple to dark blue with glowing effect
        gradient = QLinearGradient(0, 0, 1, 0)  # Dummy gradient direction
        gradient.setColorAt(1.0, QColor(50, 0, 50))  # Dark Purple
        gradient.setColorAt(0.5, QColor(0, 0, 255))  # Dark Blue
        gradient.setColorAt(0.0, QColor(0, 255, 255))  # Light Cyan/Glowing edge

        pen = QPen(QBrush(gradient), max(2, int(np.mean(np.abs(self.audio_data)) * 10)))
        pen.setCapStyle(Qt.PenCapStyle.RoundCap)
        pen.setJoinStyle(Qt.PenJoinStyle.RoundJoin)
        painter.setPen(pen)

        # 3. Draw the waveform lines
        painter.drawPolyline(waveform)

        # 4. Fill the area between the button and waveform with a semi-transparent color
        wave_fill = QPolygonF()
        wave_fill.append(QPointF(button_center.x(), button_center.y()))  # Start from center
        wave_fill += waveform
        wave_fill.append(QPointF(waveform[0].x(), waveform[0].y()))  # Close the polygon
        painter.setBrush(QColor(255, 0, 0, 50))  # Semi-transparent red
        painter.setPen(Qt.PenStyle.NoPen)  # No border for the fill
        painter.drawPolygon(wave_fill)


    def closeEvent(self, event):
        """Ensure the audio thread is stopped when the window closes."""
        self.audio_thread.stop()
        super().closeEvent(event)
    def create_dropshadow(self,parent,color:QColor,blur:float,x:float,y:float):
        dropshadow = QGraphicsDropShadowEffect(parent)
        dropshadow.setColor(color)
        dropshadow.setBlurRadius(blur)
        dropshadow.setXOffset(x)
        dropshadow.setYOffset(y)
        return dropshadow
    def istalking(self):
        if self.is_talking == False:
            self.audio_text = ""
            self.is_talking = True
            self.tt=Thread(target=listen_and_set,args=(self,))
            self.tt.start()
            time.sleep(0.5)
            self.pushtotalk.setText("Listening...")
            self.is_talking = False
        else:
            self.is_talking = False
    def retranslateUi(self,obj):
        _translate = QtCore.QCoreApplication.translate
        obj.setWindowTitle(_translate("MainWindow", "OMEGAPy-SoreUI"))
        obj.pushtotalk.setText(_translate("MainWindow", "PUSH TO TALK"))
        obj.switchtotextmodebtn.setText(_translate("MainWindow", "Switch to text"))
        obj.credits.setText(_translate("MainWindow", "Made by M1778"))

def listen_and_set(self_):
    with sr.Microphone() as source:
        r.adjust_for_ambient_noise(source,0.5)
        audio_text = r.listen(source)
        self_.pushtotalk.setText("Processing...")
        try:
            self_.audio_text = r.recognize_google(audio_text)
        except sr.UnknownValueError:
            self_.pushtotalk.setText("Resetting...")
            Thread(target=speak,args=(self_.audio_text,)).start()
            self_.audio_text = ""
            self_.is_talking = False
            self_.pushtotalk.setText("PUSH TO TALK")
            return
        print(self_.audio_text)
        Thread(target=speak,args=(self_.audio_text,)).start()
        self_.pushtotalk.setText("PUSH TO TALK")
    return self_.audio_text

def loop_in_process(self_):
    while not stop_flag.is_set():
        try:
            with sr.Microphone() as mic:
                r.adjust_for_ambient_noise(mic,0.2)
                print("GOING TO LISTEN")
                audio = r.listen(mic,timeout=3,phrase_time_limit=5)
                print("LISTEN COMPLETED, NOW RECOGNIZING")
                text = r.recognize_google(audio)
                text=text.lower()
                print(text)
                if text == "stop":
                    stop_flag.set()
                    exit(0)
                if difflib.SequenceMatcher(None,keyword,text).ratio() > 0.5:
                    print("\a")
                    self_.pushtotalk.setText("Listening...")
                    self_.is_talking=True
                    print("LISTE_AND_SET")  
                    listen_and_set(self_)
        except Exception as err:print(f"Warning: An error occured while trying to be in the main listening loop.\n{err}")

def speak(text:str):
    try:
        engine.endLoop()
    except:...
    try:
        engine.stop()
    except:...
    if text == "":
        return
    engine.setProperty("rate",175)
    engine.setProperty("voice",engine.getProperty("voices")[1].id)
    engine.say(text)
    try:
        engine.runAndWait()
    except RuntimeError:
        speak(text)
if __name__ == "__main__":
    app = QApplication(sys.argv)
    mainwindow = MainWindow()
    p = Thread(target=loop_in_process,args=(mainwindow,))
    p.start()
    mainwindow.show()
    sys.exit(app.exec())